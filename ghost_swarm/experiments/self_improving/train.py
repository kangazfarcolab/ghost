"""
Self-Improving - Experiment 3
=============================
Competitive Evolution + Dream Synthesis

Goal: Autonomous self-improvement through natural selection
Expected: Discovers optimal hyperparameters automatically

Components:
1. Competitive Evolution: Kill weak, clone strong, mutate
2. Dream Synthesis: Generate unlimited training data
"""

import sys
import os
import time
import json
import random
from typing import List, Dict, Tuple
from copy import deepcopy

# Add paths
script_dir = os.path.dirname(os.path.abspath(__file__))
experiments_dir = os.path.dirname(script_dir)
swarm_dir = os.path.dirname(experiments_dir)
base_path = os.path.dirname(swarm_dir)

sys.path.insert(0, base_path)
sys.path.insert(0, os.path.join(base_path, 'ghost_model'))
sys.path.insert(0, experiments_dir)  # For importing from other experiments

import mlx.core as mx
import mlx.nn as nn
import mlx.optimizers as optim
from mlx.utils import tree_flatten, tree_unflatten, tree_map

# Load ghost_worker using importlib
import importlib.util
ghost_worker_path = os.path.join(base_path, 'ghost_model_v7', 'core', 'ghost_worker.py')
spec = importlib.util.spec_from_file_location("ghost_worker", ghost_worker_path)
ghost_worker_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(ghost_worker_module)
GhostWorker = ghost_worker_module.GhostWorker


# ============================================================================
# EVOLUTIONARY OPERATIONS
# ============================================================================

def mutate_weights(params: Dict, mutation_rate: float = 0.01) -> Dict:
    """
    Add small random mutations to weights.
    """
    def mutate(p):
        noise = mx.random.normal(shape=p.shape) * mutation_rate
        return p + noise
    
    return tree_map(mutate, params)


def clone_model(source: GhostWorker, mutate: bool = True, mutation_rate: float = 0.01) -> GhostWorker:
    """
    Clone a model, optionally with mutations.
    """
    # Create new model with same architecture
    clone = GhostWorker(dim=source.dim, num_layers=source.num_layers)
    
    # Copy weights
    source_params = dict(tree_flatten(source.parameters()))
    
    if mutate:
        # Apply mutations
        mutated_params = mutate_weights(source_params, mutation_rate)
        clone.load_weights(list(mutated_params.items()))
    else:
        clone.load_weights(list(source_params.items()))
    
    mx.eval(clone.parameters())
    return clone


# ============================================================================
# FITNESS EVALUATION
# ============================================================================

# ============================================================================
# FITNESS EVALUATION
# ============================================================================

def pad_batch(batch_strings: List[str]) -> Tuple[mx.array, mx.array]:
    """Pad a list of strings to equal length."""
    tokenized = [[ord(c) for c in s] for s in batch_strings]
    max_len = max(len(t) for t in tokenized)
    padded = []
    masks = []
    for t in tokenized:
        pad_len = max_len - len(t)
        padded.append(t + [0] * pad_len)
        masks.append([1.0] * len(t) + [0.0] * pad_len)
    return mx.array(padded, dtype=mx.int32), mx.array(masks, dtype=mx.float32)

def evaluate_fitness(model: GhostWorker, test_data: List[Tuple[str, str]]) -> float:
    """
    Evaluate model fitness on test data (Vectorized).
    Returns accuracy (higher is better).
    """
    if not test_data:
        return 0.0
        
    questions = [q for q, a in test_data]
    answers = [a for q, a in test_data]
    
    # 1. Prepare initial batch (questions)
    x, _ = pad_batch(questions) # [B, L]
    
    # Determine max generation length
    max_gen_len = max(len(a) for a in answers)
    
    # Storage for generated bytes [B, max_gen_len]
    generated_bytes = []
    
    # 2. Autoregressive Generation (Batch)
    curr_x = x
    for _ in range(max_gen_len):
        logits = model(curr_x) # [B, L, V]
        
        # Greedy decode last token
        next_tokens = mx.argmax(logits[:, -1, :], axis=-1) # [B]
        next_tokens = next_tokens[:, None] # [B, 1]
        
        generated_bytes.append(next_tokens)
        
        # Append to input for next step
        curr_x = mx.concatenate([curr_x, next_tokens], axis=1)
    
    # 3. Calculate Accuracy
    # Stack generated bytes to [B, max_gen_len]
    gen_matrix = mx.concatenate(generated_bytes, axis=1)
    
    correct_chars = 0
    total_chars = 0
    
    # Convert back to python for easy string comparison (simpler than rigorous tensor masking here)
    gen_lists = gen_matrix.tolist()
    
    for i, gen_ids in enumerate(gen_lists):
        target_str = answers[i]
        # Truncate or use generated length up to target length
        # (The original code forced generation to match target length exactly)
        
        gen_str = "".join([chr(int(c)) if 0 <= int(c) < 128 else '?' for c in gen_ids[:len(target_str)]])
        
        for g, a in zip(gen_str, target_str):
            if g == a:
                correct_chars += 1
            total_chars += 1
            
    return correct_chars / max(total_chars, 1)


# ============================================================================
# SELF-IMPROVING TRAINER
# ============================================================================

class SelfImprovingTrainer:
    """
    Self-Improving = Competitive Evolution + Dream Synthesis
    """
    
    def __init__(self, population_size: int = 20, elite_ratio: float = 0.2):
        self.population_size = population_size
        self.elite_ratio = elite_ratio
        self.elite_count = int(population_size * elite_ratio)
        
        # Initialize population
        print(f"Initializing population of {population_size} workers...")
        self.population = []
        for i in range(population_size):
            model = GhostWorker(dim=256, num_layers=6)
            mx.eval(model.parameters())
            self.population.append({
                'model': model,
                'fitness': 0.0,
                'generation': 0,
                'optimizer': optim.Adam(learning_rate=0.001)
            })
        
        self.generation = 0
        self.history = []
    
    def compute_loss(self, model, batch_data: List[str]) -> mx.array:
        """Compute vectorized loss."""
        x, mask = pad_batch(batch_data)
        B, L = x.shape
        if L < 2: return mx.array(0.0)
        
        logits = model(x[:, :-1])
        targets = x[:, 1:]
        target_mask = mask[:, 1:]
        
        logits_flat = logits.reshape(-1, 256)
        targets_flat = targets.reshape(-1)
        
        losses = nn.losses.cross_entropy(logits_flat, targets_flat, reduction='none')
        masked_loss = losses * target_mask.reshape(-1)
        
        return masked_loss.sum() / mx.maximum(target_mask.sum(), 1.0)

    def train_population_step(self, data: List[Tuple[str, str]]):
        """Train all individuals for one step."""
        for individual in self.population:
            model = individual['model']
            optimizer = individual['optimizer']
            
            # Train on subset of data (Vectorized)
            subset = random.sample(data, min(10, len(data)))
            batch = [q + a for q, a in subset]
            
            loss_fn = lambda m: self.compute_loss(m, batch)
            loss, grads = mx.value_and_grad(loss_fn)(model)
            
            optimizer.update(model, grads)
            mx.eval(model.parameters())
    
    def evaluate_population(self, test_data: List[Tuple[str, str]]):
        """Evaluate fitness of all individuals."""
        for individual in self.population:
            individual['fitness'] = evaluate_fitness(individual['model'], test_data)
    
    def evolve(self):
        """
        Perform one evolution step:
        1. Sort by fitness
        2. Kill bottom performers
        3. Clone and mutate top performers
        """
        self.generation += 1
        
        # Sort by fitness (descending)
        self.population.sort(key=lambda x: x['fitness'], reverse=True)
        
        # Keep elite
        survivors = self.population[:self.elite_count]
        
        # Clone and mutate survivors to fill population
        new_population = []
        
        # Keep elites unchanged
        for elite in survivors:
            new_population.append({
                'model': elite['model'],
                'fitness': elite['fitness'],
                'generation': self.generation,
                'optimizer': elite['optimizer']
            })
        
        # Fill rest with mutated clones
        while len(new_population) < self.population_size:
            parent = random.choice(survivors)
            
            # Clone with mutation
            child_model = clone_model(parent['model'], mutate=True, mutation_rate=0.01)
            
            new_population.append({
                'model': child_model,
                'fitness': 0.0,
                'generation': self.generation,
                'optimizer': optim.Adam(learning_rate=0.001)
            })
        
        self.population = new_population
    
    def train(self, num_generations: int = 10, steps_per_generation: int = 10, 
              samples_per_step: int = 100, verbose: bool = False) -> Dict:
        """Train using Self-Improving strategy."""
        print("="*60)
        print("SELF-IMPROVING TRAINING (Evolutionary)")
        print(f"Population: {self.population_size}")
        print(f"Generations: {num_generations}")
        print(f"Steps/gen: {steps_per_generation}")
        print(f"Samples/step: {samples_per_step}")
        print(f"Elite ratio: {self.elite_ratio}")
        print(f"Verbose: {verbose}")
        print("="*60)
        
        total_start = time.time()
        
        # Import dream data generator
        from speed_demon.train import generate_dream_data
        
        for gen in range(num_generations):
            gen_start = time.time()
            
            if verbose:
                print(f"\n--- Generation {gen+1}/{num_generations} ---")
                print(f"  [Training] {steps_per_generation} steps for {self.population_size} individuals")
            
            # Train all individuals
            for step in range(steps_per_generation):
                data = generate_dream_data(samples_per_step)
                self.train_population_step(data)
                
                if verbose and step == 0:
                    print(f"  [Step 1] Training on {len(data)} samples...")
            
            # Evaluate fitness
            if verbose:
                print(f"  [Eval] Evaluating fitness on test data...")
            
            test_data = generate_dream_data(50)
            self.evaluate_population(test_data)
            
            # Get stats before evolution
            fitnesses = [ind['fitness'] for ind in self.population]
            best_fitness = max(fitnesses)
            avg_fitness = sum(fitnesses) / len(fitnesses)
            worst_fitness = min(fitnesses)
            
            if verbose:
                print(f"  [Fitness] Best: {best_fitness:.4f}, Avg: {avg_fitness:.4f}, Worst: {worst_fitness:.4f}")
                print(f"  [Evolve] Killing bottom {self.population_size - self.elite_count}, cloning top {self.elite_count}")
            
            # Evolve
            self.evolve()
            
            gen_time = time.time() - gen_start
            
            stats = {
                'generation': gen + 1,
                'best_fitness': best_fitness,
                'avg_fitness': avg_fitness,
                'worst_fitness': worst_fitness,
                'time': gen_time
            }
            self.history.append(stats)
            
            print(f"Gen {gen+1}/{num_generations} | "
                  f"Best: {best_fitness:.4f} | "
                  f"Avg: {avg_fitness:.4f} | "
                  f"Time: {gen_time:.2f}s")
        
        total_time = time.time() - total_start
        total_samples = num_generations * steps_per_generation * samples_per_step * self.population_size
        
        results = {
            'experiment': 'self_improving',
            'population_size': self.population_size,
            'num_generations': num_generations,
            'total_time': total_time,
            'total_samples': total_samples,
            'final_best_fitness': self.history[-1]['best_fitness'] if self.history else 0,
            'final_avg_fitness': self.history[-1]['avg_fitness'] if self.history else 0,
            'history': self.history
        }
        
        print("\n" + "="*60)
        print("RESULTS")
        print("="*60)
        print(f"Total time: {total_time:.2f}s")
        print(f"Generations: {num_generations}")
        print(f"Final best fitness: {results['final_best_fitness']:.4f}")
        print(f"Final avg fitness: {results['final_avg_fitness']:.4f}")
        
        return results
    
    def save_results(self, path: str):
        """Save training results to JSON."""
        results = {
            'experiment': 'self_improving',
            'population_size': self.population_size,
            'final_best_fitness': self.history[-1]['best_fitness'] if self.history else 0,
            'history': self.history
        }
        with open(path, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"Results saved to {path}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Self-Improving Training Experiment")
    parser.add_argument('--population', type=int, default=5, help='Population size')
    parser.add_argument('--generations', type=int, default=3, help='Number of generations')
    parser.add_argument('--steps', type=int, default=5, help='Steps per generation')
    parser.add_argument('--samples', type=int, default=20, help='Samples per step')
    parser.add_argument('--elite', type=float, default=0.2, help='Elite ratio')
    parser.add_argument('--verbose', '-v', action='store_true', help='Verbose output')
    args = parser.parse_args()
    
    trainer = SelfImprovingTrainer(population_size=args.population, elite_ratio=args.elite)
    results = trainer.train(
        num_generations=args.generations, 
        steps_per_generation=args.steps, 
        samples_per_step=args.samples,
        verbose=args.verbose
    )
    
    output_dir = os.path.dirname(os.path.abspath(__file__))
    trainer.save_results(os.path.join(output_dir, 'self_improving_results.json'))

